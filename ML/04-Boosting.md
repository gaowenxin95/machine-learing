# Boosting

>Boosting是一族可将弱学习器提升为强学习器的算法，其工作机制类似先从初始训练集训练一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的样本在后续受到更多的关注，然后基于调整后的样本分布来训练下一个基学习器，如此重复进行，直至基学习器数目达到事先指定的值T,最终将这T个基学习器进行加权。

代表
- Adaboost

## 重赋权
- boosting算法要求基学习器能对特定的数据分布进行学习，可以通过“重赋权法”实施，即在每一轮训练中，根据样本的基学习算法，根据样本分布为每个训练重新赋一个权重。

## 重采样

对于无法接受带权样本的基学习算法，则可通过重采样法进行处理，即在每一轮的学习中，根据样本分布对训练集进行重新采样，再用重采样而得的样本集对基学习器进行训练

>boosting在训练的每一轮都要检查当前生成的基学习器是否满足基本条件，否则抛弃。


从bias-variance角度看，boosting主要关注降低偏差，因此boosting能基于泛化性能相当弱的学习器构建出很强的集成
